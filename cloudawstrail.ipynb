{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14111890,"sourceType":"datasetVersion","datasetId":8989226}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:32:16.495428Z","iopub.execute_input":"2025-12-18T18:32:16.495801Z","iopub.status.idle":"2025-12-18T18:32:16.753550Z","shell.execute_reply.started":"2025-12-18T18:32:16.495777Z","shell.execute_reply":"2025-12-18T18:32:16.752837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport math\nimport gc\nimport io\nimport json\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Optional, Tuple\n\nimport pandas as pd\nimport numpy as np\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.mixture import GaussianMixture\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\n\nprint(\"tensorflow:\", tf.__version__)\n\n\nINPUT_PATH = \"/kaggle/input/clouddataset17/dec12_18features.csv\"\nOUTPUT_DIR = Path(\"/kaggle/working\")\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\nSTATE_PATH = OUTPUT_DIR / \"arf_tc_state.json\"\n\n\ndef set_deterministic(seed: int = 42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    try:\n        tf.random.set_seed(seed)\n    except Exception:\n        pass\n    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nset_deterministic(42)\nprint(\"ðŸ“Œ Deterministic helpers set; Kaggle working directory:\", OUTPUT_DIR)\n\n\ndef nowstamp():\n    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H-%M-%SZ\")\n\ndef load_state(default_models: Iterable[str], state_path: Path = STATE_PATH):\n    if state_path.exists():\n        st = json.loads(state_path.read_text())\n        st.setdefault(\"R\", {})\n        for m in default_models:\n            if m not in st[\"R\"]:\n                st[\"R\"][m] = 0.5\n        st.setdefault(\"S_prev\", {})\n        return st\n    else:\n        st = {\"R\": {m: 0.5 for m in default_models}, \"S_prev\": {}}\n        state_path.write_text(json.dumps(st, indent=2))\n        return st\n\ndef save_state(state: Dict, state_path: Path = STATE_PATH):\n    state_path.write_text(json.dumps(state, indent=2))\n\ndef softmax(xs: np.ndarray, alpha: float = 1.0) -> np.ndarray:\n    e = np.exp(alpha * (xs - np.nanmax(xs)))\n    denom = np.nansum(e)\n    if denom == 0:\n        e = np.ones_like(e)\n        denom = e.sum()\n    return e / denom\n\ndef minmax_normalize_array(arr: np.ndarray, eps: float = 1e-9) -> np.ndarray:\n    mn = np.nanmin(arr)\n    mx = np.nanmax(arr)\n    rng = mx - mn\n    if rng < eps:\n        return np.zeros_like(arr, dtype=float)\n    return (arr - mn) / (rng + eps)\n\ndef compute_precision_at_k(y_true: np.ndarray, scores: np.ndarray, k: int = 10) -> float:\n    if len(y_true) == 0:\n        return 0.0\n    k = min(k, len(y_true))\n    order = np.argsort(-scores)\n    topk = order[:k]\n    return float(np.sum(y_true[topk]) / k)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:32:21.466401Z","iopub.execute_input":"2025-12-18T18:32:21.467033Z","iopub.status.idle":"2025-12-18T18:32:36.896523Z","shell.execute_reply.started":"2025-12-18T18:32:21.466979Z","shell.execute_reply":"2025-12-18T18:32:36.895800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom typing import Any\n\nclass ARFTC:\n    def __init__(\n        self,\n        model_names: List[str] = [\"gmm\", \"ae\", \"if\"],\n        eta: float = 0.12,\n        alpha: float = 8.0,\n        gamma: float = 0.45,\n        beta: float = 0.7,\n        lam: float = 0.18,\n        tau: float = 0.6,\n        k_for_perf: int = 10,\n        state_path: Path = STATE_PATH\n    ):\n        self.model_names = list(model_names)\n        self.eta = eta\n        self.alpha = alpha\n        self.gamma = gamma\n        self.beta = beta\n        self.lam = lam\n        self.tau = tau\n        self.k_for_perf = k_for_perf\n        self.state_path = state_path\n        self.state = load_state(self.model_names, state_path=self.state_path)\n\n    def update_reliabilities(self, val_labels: np.ndarray, val_scores: Dict[str, np.ndarray]):\n        for m in self.model_names:\n            scores = val_scores[m]\n            perf = compute_precision_at_k(val_labels, scores, k=self.k_for_perf)\n            R_prev = float(self.state[\"R\"].get(m, 0.5))\n            R_new = (1 - self.eta) * R_prev + self.eta * perf\n            self.state[\"R\"][m] = float(R_new)\n        save_state(self.state, state_path=self.state_path)\n\n    def compute_weights(self) -> Dict[str, float]:\n        Rs = np.array([self.state[\"R\"].get(m, 0.5) for m in self.model_names], dtype=float)\n        ws = softmax(Rs, alpha=self.alpha)\n        return {m: float(ws[i]) for i, m in enumerate(self.model_names)}\n\n    def fuse_batch(\n        self,\n        df: pd.DataFrame,\n        model_score_cols: Dict[str, str],\n        user_col: str = \"user\",\n        sample_col: Optional[str] = None,\n        timestamp_col: Optional[str] = None,\n        normalize_mode: str = \"batch\",\n    ) -> pd.DataFrame:\n        assert set(self.model_names) <= set(model_score_cols.keys()), \"Missing model score columns.\"\n        normalized = {}\n        for m in self.model_names:\n            arr = df[model_score_cols[m]].values.astype(float)\n            if normalize_mode == \"batch\":\n                normalized[m] = minmax_normalize_array(arr)\n            elif normalize_mode == \"zsig\":\n                z = (arr - np.nanmean(arr)) / (np.nanstd(arr) + 1e-9)\n                normalized[m] = 1 / (1 + np.exp(-z))\n            else:\n                normalized[m] = minmax_normalize_array(arr)\n\n        norm_arr = np.vstack([normalized[m] for m in self.model_names]).T\n\n        Rs = np.array([self.state[\"R\"].get(m, 0.5) for m in self.model_names], dtype=float)\n        weights = softmax(Rs, alpha=self.alpha)\n        weight_map = {m: float(weights[i]) for i, m in enumerate(self.model_names)}\n\n        S_raw = np.dot(norm_arr, weights)\n\n        var_per_sample = np.nanvar(norm_arr, axis=1)\n        var_max = max(var_per_sample.max(), 1e-9)\n        D = var_per_sample / var_max\n\n        S_disc = S_raw * (1 - self.gamma * D)\n        S_disc = np.clip(S_disc, 0.0, 1.0)\n\n        S_smoothed = np.zeros_like(S_disc)\n        users = df[user_col].astype(str).values if user_col in df.columns else df.index.astype(str).values\n        for i, user in enumerate(users):\n            prev = float(self.state[\"S_prev\"].get(user, 0.0))\n            S_smoothed[i] = self.beta * S_disc[i] + (1 - self.beta) * prev\n            self.state[\"S_prev\"][user] = float(S_smoothed[i])\n\n        uncertainty = D\n        conf = S_smoothed * (1 - self.lam * uncertainty)\n        conf = np.clip(conf, 0.0, 1.0)\n\n        contributions = {f\"contrib_{m}\": norm_arr[:, i] * float(weights[i]) for i, m in enumerate(self.model_names)}\n\n        out = df.copy()\n        out[\"fused_raw\"] = S_raw\n        out[\"fused_disc\"] = S_disc\n        out[\"fused_smoothed\"] = S_smoothed\n        out[\"conf_score\"] = conf\n        out[\"final_label\"] = (conf >= self.tau).astype(int)\n        for m in self.model_names:\n            out[f\"norm_{m}\"] = normalized[m]\n            out[f\"contrib_{m}\"] = contributions[f\"contrib_{m}\"]\n\n        save_state(self.state, state_path=self.state_path)\n        out.attrs[\"arf_tc_weights\"] = weight_map\n        out.attrs[\"arf_tc_reliabilities\"] = self.state[\"R\"].copy()\n        return out\n\n    def evaluate_and_update_window(\n        self,\n        df_val: pd.DataFrame,\n        val_label_col: str,\n        val_model_score_cols: Dict[str, str],\n        df_score_out: Optional[pd.DataFrame] = None,\n    ) -> Tuple[Dict[str, float], pd.DataFrame]:\n        val_labels = df_val[val_label_col].values.astype(int)\n        val_scores = {m: df_val[val_model_score_cols[m]].values.astype(float) for m in self.model_names}\n        self.update_reliabilities(val_labels, val_scores)\n        weights = self.compute_weights()\n        if df_score_out is not None:\n            scored = self.fuse_batch(df_score_out, val_model_score_cols)\n            return weights, scored\n        else:\n            return weights, df_val\n\nprint(\"âœ… ARF-TC class ready (Kaggle-compatible)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:32:38.035337Z","iopub.execute_input":"2025-12-18T18:32:38.036135Z","iopub.status.idle":"2025-12-18T18:32:38.055572Z","shell.execute_reply.started":"2025-12-18T18:32:38.036110Z","shell.execute_reply":"2025-12-18T18:32:38.054785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"âš™ï¸ Pipeline configuration and PASS 1 sampling...\")\n\nINPUT_CSV = INPUT_PATH \nCHUNK_SIZE = 5000\nSAMPLE_LIMIT = 20000\nTRAIN_GMM = True\nTRAIN_AE = True\nISO_N_EST = 200\nRANDOM_STATE = 42\n\nprint(\"Input CSV path:\", INPUT_CSV)\nprint(\"Output directory:\", OUTPUT_DIR)\n\nIDENTIFIERS = [\n    'eventID', 'eventTime', 'userIdentityuserName', 'userIdentityarn', 'userIdentityaccessKeyId',\n    'userIdentityprincipalId', 'userIdentityaccountId', 'errorCode', 'errorMessage'\n]\n\nREGION_MAP = {}\nregion_counter = 1\nEVENT_MAP = {}\nevent_counter = 1\n\ndef encode_region(region):\n    global REGION_MAP, region_counter\n    if pd.isna(region):\n        return 0\n    if region not in REGION_MAP:\n        REGION_MAP[region] = region_counter\n        region_counter += 1\n    return REGION_MAP[region]\n\ndef encode_event(event):\n    global EVENT_MAP, event_counter\n    if pd.isna(event):\n        return 0\n    if event not in EVENT_MAP:\n        EVENT_MAP[event] = event_counter\n        event_counter += 1\n    return EVENT_MAP[event]\n\nprint(\"Starting PASS 1: sampling...\")\n\nreader = pd.read_csv(INPUT_CSV, chunksize=CHUNK_SIZE)\nsample_chunks = []\nsampled_rows = 0\ntotal_seen = 0\n\nfor idx, chunk in enumerate(reader, start=1):\n    print(f\"âž¡ PASS 1 â€” chunk #{idx}\")\n    total_seen += len(chunk)\n    chunk = chunk.fillna(np.nan)\n\n    work = chunk.drop(columns=IDENTIFIERS, errors=\"ignore\")\n\n    if \"awsRegion\" in work.columns:\n        work[\"awsRegionEnc\"] = work[\"awsRegion\"].apply(encode_region)\n        work = work.drop(columns=[\"awsRegion\"], errors=\"ignore\")\n\n    if \"eventName\" in work.columns:\n        work[\"eventNameEnc\"] = work[\"eventName\"].apply(encode_event)\n        work = work.drop(columns=[\"eventName\"], errors=\"ignore\")\n\n    for c in work.columns:\n        if work[c].dtype == \"object\":\n            work[c] = pd.to_numeric(work[c], errors=\"coerce\")\n\n    numeric = work.select_dtypes(include=[np.number]).replace([np.inf, -np.inf], np.nan).fillna(0)\n\n    if numeric.shape[1] == 0:\n        print(\"âš  No numeric features in this chunk, skipping.\")\n        continue\n\n    remaining = SAMPLE_LIMIT - sampled_rows\n    take = min(1000, remaining, len(numeric))\n\n    if take > 0:\n        sample = numeric.sample(n=take, random_state=RANDOM_STATE)\n        sample_chunks.append(sample)\n        sampled_rows += take\n\n    print(f\"   â€¢ rows seen: {total_seen:,}, sample collected: {sampled_rows:,}\")\n\n    gc.collect()\n    if sampled_rows >= SAMPLE_LIMIT:\n        print(\"Reached sample limit.\")\n        break\n\nif len(sample_chunks) == 0:\n    raise RuntimeError(\"No training samples collected. Check the input file path and chunk size.\")\n\nprint(\"PASS 1 complete â€” sample size:\", sampled_rows)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:32:41.795482Z","iopub.execute_input":"2025-12-18T18:32:41.795738Z","iopub.status.idle":"2025-12-18T18:32:46.731514Z","shell.execute_reply.started":"2025-12-18T18:32:41.795720Z","shell.execute_reply":"2025-12-18T18:32:46.730764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"ðŸ§¹ Cleaning sample and training models...\")\n\nsample_df = pd.concat(sample_chunks, ignore_index=True)\nsample_df = sample_df.replace([np.inf, -np.inf], np.nan).fillna(0)\nsample_df = sample_df.astype(float)\n\nprint(\"Sample shape:\", sample_df.shape)\n\nvar = sample_df.var(skipna=True)\nkeep_cols = var[var > 0].index.tolist()\nsample_df = sample_df[keep_cols]\n\nprint(\"Usable features for training:\", sample_df.shape[1])\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(sample_df)\ntrain_cols = sample_df.columns.tolist()\n\n\nprint(\"ðŸŒ² Training IsolationForest...\")\niso = IsolationForest(n_estimators=ISO_N_EST, contamination=0.03, random_state=RANDOM_STATE)\niso.fit(X_train)\nprint(\"IF trained\")\n\n\ngmm = None\nif TRAIN_GMM:\n    print(\"ðŸ“ˆ Training GMM...\")\n    try:\n        gmm = GaussianMixture(n_components=3, covariance_type=\"full\", random_state=RANDOM_STATE)\n        gmm.fit(X_train)\n        print(\"GMM trained\")\n    except Exception as e:\n        print(\"GMM failed:\", e)\n        gmm = None\n        TRAIN_GMM = False\n\n\nauto = None\nif TRAIN_AE:\n    print(\"ðŸ§  Training Autoencoder (TF)...\")\n    try:\n        input_dim = X_train.shape[1]\n        inp = Input(shape=(input_dim,))\n        e = Dense(max(8, input_dim//4), activation=\"relu\")(inp)\n        e = Dense(max(4, input_dim//8), activation=\"relu\")(e)\n        d = Dense(max(8, input_dim//4), activation=\"relu\")(e)\n        out = Dense(input_dim)(d)\n\n        auto = Model(inp, out)\n        auto.compile(optimizer=\"adam\", loss=\"mse\")\n        auto.fit(X_train, X_train, epochs=10, batch_size=64, verbose=1)\n        recon_train = auto.predict(X_train, verbose=0)\n        train_err = ((X_train - recon_train)**2).mean(axis=1)\n        auto._ae_thresh = train_err.mean() + 2*train_err.std()\n        print(\"Autoencoder trained; threshold set\")\n    except Exception as e:\n        print(\"Autoencoder failed:\", e)\n        auto = None\n        TRAIN_AE = False\n\nprint(\"âœ… Models training done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:32:52.415579Z","iopub.execute_input":"2025-12-18T18:32:52.416371Z","iopub.status.idle":"2025-12-18T18:33:06.548005Z","shell.execute_reply.started":"2025-12-18T18:32:52.416347Z","shell.execute_reply":"2025-12-18T18:33:06.547288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"ðŸš€ PASS 2: Scoring and ARF-TC fusion...\")\n\nreader = pd.read_csv(INPUT_CSV, chunksize=CHUNK_SIZE)\ntmp_output = OUTPUT_DIR / f\"anomalous_users_{nowstamp()}.csv\"\nprint(\"Temporary output:\", tmp_output)\n\narf = ARFTC(model_names=[\"gmm\", \"ae\", \"if\"], eta=0.12, alpha=8.0, gamma=0.45, beta=0.7, lam=0.18, tau=0.6)\n\nfirst_write = True\ntotal_anomalies = 0\ntotal_rows_processed = 0\n\nprint(\"Initial reliabilities:\", arf.state[\"R\"])\n\nfor idx, chunk in enumerate(reader, start=1):\n    print(f\"âž¡ PASS 2 â€” chunk #{idx}\")\n    orig = chunk.copy()\n    work = chunk.drop(columns=IDENTIFIERS, errors=\"ignore\")\n\n    if \"awsRegion\" in work.columns:\n        work[\"awsRegionEnc\"] = work[\"awsRegion\"].apply(lambda r: REGION_MAP.get(r, 0))\n        work = work.drop(columns=[\"awsRegion\"], errors=\"ignore\")\n    if \"eventName\" in work.columns:\n        work[\"eventNameEnc\"] = work[\"eventName\"].apply(lambda e: EVENT_MAP.get(e, 0))\n        work = work.drop(columns=[\"eventName\"], errors=\"ignore\")\n\n    for c in work.columns:\n        if work[c].dtype == \"object\":\n            work[c] = pd.to_numeric(work[c], errors=\"coerce\")\n\n    numeric = work.select_dtypes(include=[np.number]).replace([np.inf,-np.inf],np.nan).fillna(0)\n    numeric = numeric.reindex(columns=train_cols, fill_value=0)\n\n    X = scaler.transform(numeric)\n\n   \n    if_score_raw = iso.decision_function(X)        \n    if_flag  = (iso.predict(X) == -1).astype(int)\n\n \n    if gmm is not None:\n        gmm_score_raw = gmm.score_samples(X)      \n        try:\n            gmm_thresh = np.percentile(gmm.score_samples(X_train), 5)\n        except Exception:\n            gmm_thresh = gmm_score_raw.mean() - 2*gmm_score_raw.std()\n        gmm_flag = (gmm_score_raw < gmm_thresh).astype(int)\n    else:\n        gmm_score_raw = np.zeros(len(X))\n        gmm_flag = np.zeros(len(X), dtype=int)\n\n    \n    if auto is not None:\n        recon = auto.predict(X, verbose=0)\n        ae_err = ((X - recon)**2).mean(axis=1)\n        ae_flag = (ae_err > getattr(auto, \"_ae_thresh\", ae_err.mean() + 2*ae_err.std())).astype(int)\n    else:\n        ae_err = np.zeros(len(X))\n        ae_flag = np.zeros(len(X), dtype=int)\n\n    \n    if_anom = -if_score_raw\n    gmm_anom = -gmm_score_raw\n    ae_anom = ae_err\n\n    scoring_df = orig.copy()\n    scoring_df[\"score_gmm\"] = gmm_anom\n    scoring_df[\"score_ae\"]  = ae_anom\n    scoring_df[\"score_if\"]  = if_anom\n\n    \n    user_col = None\n    candidate_user_cols = [\n        \"userIdentityuserName\", \"userIdentity.userName\", \"userName\", \"sourceIPAddress\"\n    ]\n    for c in candidate_user_cols:\n        if c in scoring_df.columns:\n            user_col = c\n            break\n    if user_col is None:\n        scoring_df[\"__user_synthetic\"] = scoring_df.index.astype(str)\n        user_col = \"__user_synthetic\"\n\n    model_score_cols = {\"gmm\": \"score_gmm\", \"ae\": \"score_ae\", \"if\": \"score_if\"}\n\n    fused = arf.fuse_batch(scoring_df, model_score_cols=model_score_cols, user_col=user_col, normalize_mode=\"batch\")\n\n    anomalies = fused[fused[\"final_label\"] == 1].copy()\n\n    total_rows_processed += len(fused)\n    total_anomalies += len(anomalies)\n\n    print(f\"   â€¢ rows in chunk: {len(fused)}\")\n    print(f\"   â€¢ anomalies in chunk: {len(anomalies)}  (total so far: {total_anomalies})\")\n\n    if len(anomalies) > 0:\n        save_cols = list(orig.columns) + [\n            \"score_gmm\",\"score_ae\",\"score_if\",\n            \"fused_raw\",\"fused_disc\",\"fused_smoothed\",\"conf_score\",\"final_label\",\n            \"contrib_gmm\",\"contrib_ae\",\"contrib_if\"\n        ]\n        save_cols = [c for c in save_cols if c in anomalies.columns]\n        mode = \"w\" if first_write else \"a\"\n        header = first_write\n        anomalies.to_csv(tmp_output, index=False, mode=mode, header=header)\n        first_write = False\n\n    print(\"   â€¢ ARF-TC weights:\", fused.attrs.get(\"arf_tc_weights\"))\n    print(\"   â€¢ ARF-TC reliabilities:\", fused.attrs.get(\"arf_tc_reliabilities\"))\n\n    gc.collect()\n\nprint(\"PASS 2 complete\")\nprint(\"Total rows processed:\", total_rows_processed)\nprint(\"Total anomalies found:\", total_anomalies)\nprint(\"Anomalies saved to:\", tmp_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:33:11.285900Z","iopub.execute_input":"2025-12-18T18:33:11.286611Z","iopub.status.idle":"2025-12-18T18:39:40.440493Z","shell.execute_reply.started":"2025-12-18T18:33:11.286583Z","shell.execute_reply":"2025-12-18T18:39:40.439546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tmp_output = OUTPUT_DIR / f\"anomalous_users_{nowstamp()}.csv\"\n\nprint(\"Files in /kaggle/working/:\")\nfor p in sorted(OUTPUT_DIR.iterdir()):\n    print(\" -\", p.name)\n\nprint(\"Done. Your anomaly CSV(s) are in /kaggle/working â€” open them from Kaggle UI or with pandas.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:39:52.105827Z","iopub.execute_input":"2025-12-18T18:39:52.106084Z","iopub.status.idle":"2025-12-18T18:39:52.111698Z","shell.execute_reply.started":"2025-12-18T18:39:52.106066Z","shell.execute_reply":"2025-12-18T18:39:52.111023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, glob\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom textwrap import shorten\n\n\nWORK_DIR = Path(\"/kaggle/working\")\nFIG_DIR = WORK_DIR / \"figures\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\n\ncand_files = sorted(glob.glob(str(WORK_DIR / \"anomalous_users*.csv\")) + glob.glob(str(WORK_DIR / \"*.csv\")))\nif len(cand_files) == 0:\n    raise FileNotFoundError(\"No CSV found in /kaggle/working/. Place your output CSV there or set DATA_CSV explicitly.\")\nDATA_CSV = cand_files[-1]\nprint(\"Using CSV:\", DATA_CSV)\n\n\ndf = pd.read_csv(DATA_CSV, low_memory=False)\nprint(f\"Loaded {len(df):,} rows Ã— {len(df.columns):,} cols\")\n\n\nif 'eventTime' in df.columns:\n    try:\n        df['eventTime'] = pd.to_datetime(df['eventTime'])\n    except Exception:\n        print(\"Warning: eventTime parsing failed â€” leaving raw.\")\n\n\nscore_cols = ['score_gmm','score_ae','score_if','norm_gmm','norm_ae','norm_if',\n              'contrib_gmm','contrib_ae','contrib_if','fused_raw','fused_disc','fused_smoothed','conf_score','final_label']\nfor c in score_cols:\n    if c not in df.columns:\n        df[c] = np.nan\n\n\nplt.rcParams.update({\n    'figure.dpi': 100,\n    'savefig.dpi': 300,\n    'font.size': 10,\n    'axes.titlesize': 11,\n    'axes.labelsize': 10,\n    'legend.fontsize': 9,\n    'xtick.labelsize': 9,\n    'ytick.labelsize': 9,\n    'axes.grid': True,\n    'grid.color': '#e6e6e6'\n})\nsns.set_style(\"whitegrid\")\nprint(\"Figure dir:\", FIG_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:40:05.179980Z","iopub.execute_input":"2025-12-18T18:40:05.180883Z","iopub.status.idle":"2025-12-18T18:40:06.349542Z","shell.execute_reply.started":"2025-12-18T18:40:05.180847Z","shell.execute_reply":"2025-12-18T18:40:06.348772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nuser_col = None\nfor cand in ['userIdentityuserName', 'userName', 'sourceIPAddress']:\n    if cand in df.columns:\n        user_col = cand\n        break\n\nevent_col = None\nfor ec in ['eventName', 'eventNameEnc']:\n    if ec in df.columns:\n        event_col = ec\n        break\n\nif user_col is None:\n    print(\"No user-like column found; skipping Top-K user drilldown.\")\n\nelse:\n    \n    agg = (\n        df.groupby(user_col)\n          .agg(\n              anomaly_count=('final_label', 'sum'),\n              sum_conf=('conf_score', 'sum'),     \n              event_count=('conf_score', 'count')\n          )\n          .reset_index()\n    )\n\n    \n    agg = agg[agg['anomaly_count'] > 0]\n    agg = agg.sort_values('anomaly_count', ascending=False)\n\n    TOPK = min(20, len(agg))\n    topk = agg.head(TOPK)\n\n    \n    if event_col is not None:\n        top_event = (\n            df[df['final_label'] == 1]             \n              .groupby([user_col, event_col])\n              .size()\n              .reset_index(name='cnt')\n              .sort_values('cnt', ascending=False)\n              .drop_duplicates(user_col)\n        )\n\n        topk = topk.merge(\n            top_event[[user_col, event_col, 'cnt']],\n            on=user_col,\n            how='left'\n        ).rename(columns={\n            event_col: 'top_event',\n            'cnt': 'top_event_count'\n        })\n    else:\n        topk['top_event'] = 'N/A'\n        topk['top_event_count'] = 0\n\n    \n    fig, ax = plt.subplots(figsize=(max(6, 0.45 * TOPK), 6))\n\n    sns.barplot(\n        data=topk,\n        x=user_col,\n        y='anomaly_count',\n        palette='magma',\n        ax=ax\n    )\n\n    ax.set_title(f\"Top {TOPK} users by number of anomalous events\")\n    ax.set_xlabel(user_col)\n    ax.set_ylabel(\"Anomalous event count\")\n    ax.tick_params(axis='x', rotation=45)\n    ax.grid(axis='y', linestyle='--', alpha=0.4)\n\n    out_bar = FIG_DIR / f\"05_top{TOPK}_users_by_anomaly_count_vertical.png\"\n    fig.savefig(out_bar, bbox_inches='tight', dpi=300)\n    print(\"Saved:\", out_bar)\n    plt.show()\n\n    \n    if 'eventTime' in df.columns:\n        top_users = topk[user_col].tolist()[:6]\n\n        fig, axes = plt.subplots(\n            3, 2, figsize=(11, 8),\n            sharey=True,\n            constrained_layout=True\n        )\n        axes = axes.flatten()\n\n        for ax, u in zip(axes, top_users):\n            sub = (\n                df[(df[user_col] == u) & (df['final_label'] == 1)]\n                  .set_index('eventTime')\n                  .resample('6H')\n                  .agg({'conf_score': 'mean'})\n                  .fillna(0)\n            )\n\n            sub['conf_score'].plot(ax=ax, legend=False)\n            svc = topk.loc[topk[user_col] == u, 'top_event'].values[0]\n\n            ax.set_title(f\"{u}\\nDominant service: {svc}\")\n            ax.set_ylim(0, 1)\n            ax.set_xlabel('')\n\n        for ax in axes[len(top_users):]:\n            ax.set_visible(False)\n\n        out_small = FIG_DIR / \"05_topk_users_timelines_by_anomaly.png\"\n        fig.savefig(out_small, bbox_inches='tight', dpi=300)\n        print(\"Saved:\", out_small)\n        plt.show()\n\n    \n    print(\"\\nðŸ”Ž Top-K User â†’ Anomaly Frequency & Service Context\")\n    display(\n        topk[[\n            user_col,\n            'anomaly_count',\n            'event_count',\n            'sum_conf',\n            'top_event',\n            'top_event_count'\n        ]]\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:58:18.750172Z","iopub.execute_input":"2025-12-18T18:58:18.750621Z","iopub.status.idle":"2025-12-18T18:58:23.489340Z","shell.execute_reply.started":"2025-12-18T18:58:18.750592Z","shell.execute_reply":"2025-12-18T18:58:23.488630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if ('fused_raw' not in df.columns) or ('fused_disc' not in df.columns):\n    print(\"Missing fused_raw or fused_disc â€” skipping disagreement penalty visualization.\")\nelse:\n    # Sample for scatter readability\n    sample = df.sample(n=min(5000, max(1000, len(df))), random_state=42)\n    fig, ax = plt.subplots(1,2, figsize=(12,4), constrained_layout=True)\n\n    sc = ax[0].scatter(sample['fused_raw'], sample['fused_disc'],\n                       c=sample.get('conf_score', np.zeros(len(sample))), cmap='viridis',\n                       s=12, alpha=0.7, edgecolors='none')\n    ax[0].plot([0,1],[0,1],'k--', linewidth=0.8)\n    ax[0].set_xlabel('Fused (raw)')\n    ax[0].set_ylabel('Fused (disagreement-penalized)')\n    ax[0].set_title('Fused raw vs disagreement-penalized (sample)')\n    cbar = fig.colorbar(sc, ax=ax[0], pad=0.02)\n    cbar.set_label('conf_score')\n\n    # delta histogram\n    df['disc_delta'] = (df['fused_raw'].fillna(0) - df['fused_disc'].fillna(0))\n    sns.histplot(df['disc_delta'].dropna(), bins=80, kde=True, ax=ax[1], color='#d95f02')\n    ax[1].set_title('Distribution of disagreement penalty: fused_raw âˆ’ fused_disc')\n    ax[1].set_xlabel('Delta (penalty)')\n    ax[1].set_ylabel('Count')\n\n    out1 = FIG_DIR / \"02_disagreement_raw_vs_disc.png\"\n    out2 = FIG_DIR / \"02_disagreement_delta_hist.png\"\n    fig.savefig(out1, bbox_inches='tight')\n    # save the histogram separately at high quality\n    fig_hist, axh = plt.subplots(figsize=(6,3))\n    sns.histplot(df['disc_delta'].dropna(), bins=80, kde=True, ax=axh, color='#d95f02')\n    axh.set_title('Distribution of disagreement penalty')\n    axh.set_xlabel('Delta')\n    fig_hist.savefig(out2, bbox_inches='tight', dpi=300)\n    print(\"Saved:\", out1, \"and\", out2)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:41:47.975650Z","iopub.execute_input":"2025-12-18T18:41:47.975900Z","iopub.status.idle":"2025-12-18T18:41:50.452261Z","shell.execute_reply.started":"2025-12-18T18:41:47.975882Z","shell.execute_reply":"2025-12-18T18:41:50.451511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols = ['score_gmm', 'score_ae', 'score_if', 'conf_score']\navailable = [c for c in cols if c in df.columns and df[c].notna().any()]\n\nif available:\n    ncols = len(available)\n    \n    fig, axes = plt.subplots(1, ncols, figsize=(3.5 * ncols, 3.5))\n    if ncols == 1: axes = [axes]\n\n    colors = sns.color_palette(\"viridis\", n_colors=len(available))\n\n    for ax, col, color in zip(axes, available, colors):\n        data = df[col].dropna()\n\n        \n        sns.histplot(data, bins=50, kde=True, stat='density',\n                     color=color, edgecolor=None, alpha=0.6, ax=ax)\n\n        \n        clean_title = col.replace('_', ' ').replace('score', '').upper().strip()\n        if clean_title == \"CONF SCORE\": clean_title = \"FUSED CONFIDENCE\"\n\n        ax.set_title(clean_title, fontweight='bold')\n        ax.set_xlabel(\"Score Value\")\n        ax.set_ylabel(\"Density\")\n\n        \n        mu, med, std = data.mean(), data.median(), data.std()\n        stats_text = (f\"$\\mu={mu:.2f}$\\n\"\n                      f\"Med$={med:.2f}$\\n\"\n                      f\"$\\sigma={std:.2f}$\")\n        \n        ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,\n                fontsize=9, va='top', ha='right',\n                bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"white\", ec=\"#d9d9d9\", alpha=0.9))\n\n    out_path = FIG_DIR / f\"01_score_distributions{SUFFIX}.png\"\n    plt.savefig(out_path, bbox_inches='tight')\n    print(f\"Saved: {out_path}\")\n    plt.show()\nelse:\n    print(\"No score columns found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:42:51.595534Z","iopub.execute_input":"2025-12-18T18:42:51.596191Z","iopub.status.idle":"2025-12-18T18:42:54.918268Z","shell.execute_reply.started":"2025-12-18T18:42:51.596168Z","shell.execute_reply":"2025-12-18T18:42:54.917541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'eventTime' in df.columns:\n    \n    ts = df.set_index('eventTime').sort_index()\n   \n    ts['is_anomaly'] = (ts['conf_score'] > 0.5).astype(int)\n    \n    \n    resampled = ts.resample('1H').agg({\n        'is_anomaly': 'sum',\n        'conf_score': 'mean'\n    }).fillna(0)\n\n    \n    fig, ax1 = plt.subplots(figsize=(10, 5))\n\n    \n    color_bar = '#8da0cb' \n    ax1.bar(resampled.index, resampled['is_anomaly'], color=color_bar, \n            width=0.03, label='Anomaly Count (Hourly)')\n    ax1.set_xlabel(\"Date (UTC)\")\n    ax1.set_ylabel(\"Anomaly Count\", color=color_bar, fontweight='bold')\n    ax1.tick_params(axis='y', labelcolor=color_bar)\n\n    \n    ax2 = ax1.twinx()\n    color_line = '#fc8d62' \n    ax2.plot(resampled.index, resampled['conf_score'], color=color_line, \n             linewidth=2, linestyle='-', label='Avg Confidence Score')\n    ax2.set_ylabel(\"Mean Confidence Score\", color=color_line, fontweight='bold')\n    ax2.tick_params(axis='y', labelcolor=color_line)\n    ax2.set_ylim(0, 1.1)\n\n    \n    plt.title(\"Temporal Distribution: Anomaly Frequency vs. Severity\")\n    \n    \n    ax1.grid(True, alpha=0.3)\n    ax2.grid(False) \n\n    out_path = FIG_DIR / f\"04_temporal_analysis{SUFFIX}.png\"\n    plt.savefig(out_path, bbox_inches='tight')\n    print(f\"Saved: {out_path}\")\n    plt.show()\nelse:\n    print(\"eventTime missing.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:43:12.965117Z","iopub.execute_input":"2025-12-18T18:43:12.966128Z","iopub.status.idle":"2025-12-18T18:44:03.439198Z","shell.execute_reply.started":"2025-12-18T18:43:12.966097Z","shell.execute_reply":"2025-12-18T18:44:03.438486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\nfeat_cols = ['score_gmm','score_ae','score_if','norm_gmm','norm_ae','norm_if']\nfeatures = [c for c in feat_cols if c in df.columns]\n\nif len(features) >= 2:\n    \n    X = df[features].fillna(0)\n    pca = PCA(n_components=2, random_state=42)\n    X_pca = pca.fit_transform(X)\n    var_exp = pca.explained_variance_ratio_.sum() * 100\n\n    \n    fig, ax = plt.subplots(figsize=(7, 6))\n    \n    \n    sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], \n                    c=df['conf_score'].fillna(0), \n                    cmap='Spectral_r', \n                    s=20, alpha=0.7, edgecolors='w', linewidth=0.2)\n    \n    ax.set_xlabel(f\"Principal Component 1 ({pca.explained_variance_ratio_[0]:.1%})\")\n    ax.set_ylabel(f\"Principal Component 2 ({pca.explained_variance_ratio_[1]:.1%})\")\n    ax.set_title(f\"Total Variance Explained: {var_exp:.1f}%\")\n    \n   \n    cbar = plt.colorbar(sc, ax=ax)\n    cbar.set_label(\"Anomaly Confidence Score\")\n    cbar.ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1f'))\n\n    \n    ax.grid(True, linestyle='--', alpha=0.4)\n\n    out_path = FIG_DIR / f\"07_pca_projection{SUFFIX}.png\"\n    plt.savefig(out_path, bbox_inches='tight')\n    print(f\"Saved: {out_path}\")\n    plt.show()\nelse:\n    print(\"Not enough features for PCA.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:44:13.500061Z","iopub.execute_input":"2025-12-18T18:44:13.500809Z","iopub.status.idle":"2025-12-18T18:44:15.302373Z","shell.execute_reply.started":"2025-12-18T18:44:13.500784Z","shell.execute_reply":"2025-12-18T18:44:15.301505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}